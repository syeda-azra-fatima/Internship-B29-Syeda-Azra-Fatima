---
title: "logistic regression"
author: "Syeda azra"
date: "19 September 2017"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}

rm(list=ls(all=TRUE))

setwd("C:\\Users\\Hi\\Desktop\\internship")

mydata<-read.csv("nursery.csv",header=F,sep=",")
dim(mydata)
summary(mydata$V9)
```








```{r}
colnames(mydata) <- c("parents","has_nurs","form","children","housing","finance","social","health","Class")

str(mydata)
summary(mydata)
unique.array(mydata)
```


```{r}
#combinting the columns
mydata$Class<-as.character(mydata$Class)
mydata$Class[mydata$Class=="recommend"]="very_recom"
mydata$Class<-as.factor(mydata$Class)
summary(mydata$Class)
```



```{r}
sum(is.na(mydata))
```


```{r}
library(dummies)

mydata1<- dummy.data.frame(mydata, sep = ".")
mydata1<- mydata[,-9]
mydata1<- dummy.data.frame(mydata1,sep=".")

names(mydata1)
mydata1$Class<-mydata$Class
mydata1
```



```{r}
library(caret)
library(caTools)
library(MASS)
```


```{r}
#data partitioning

set.seed(1234)

train_rows<- createDataPartition(mydata1$Class, p = 0.7,list = F)

train <- mydata1[train_rows, ]

test  <- mydata1[-train_rows, ]

summary(test$Class)
summary(train$Class)

```




```{r}
#spliting class levels

train$Class<-as.character(train$Class)
#####

 # train_not_pr<-train[which(train$Class %in% "not_recom" | train$Class %in% "priority"),]
# table(train_not_pr$Class)
# train_not_pr$Class<-as.factor(train_not_pr$Class)
#head(train)

#not_recom  priority 
#     3024      2987
######

# train_not_specpr<-train[which(train$Class %in% "not_recom" | train$Class %in% "spec_prior"),]
# table(train_not_specpr$Class)
# train_not_specpr$Class<-as.factor(train_not_specpr$Class)

#not_recom spec_prior 
 #     3024       2831 

########
train_not_vrecom<-train[which(train$Class %in% "not_recom" | train$Class %in% "very_recom"),]
table(train_not_vrecom$Class)
train_not_vrecom$Class<-as.factor(train_not_vrecom$Class)


 #not_recom very_recom 
#    3024        231 

#str(train)
#table(train$Class)

train_remaining<-train[which(train$Class %in% "priority" | train$Class %in% "spec_prior"),]

###########

train$Class<-as.factor(train$Class)

 #summary(train_not_pr$Class)
```


```{r}
#smoting
library(dplyr)
library(DMwR)
train_not_vrecom$Class<-as.factor(train_not_vrecom$Class)
class(train_not_vrecom)
train_not_vrecom<-SMOTE(Class~., data = train_not_vrecom , perc.over =900,perc.under = 170,K=15)

summary(train_not_vrecom$Class)

```


```{r}
# combining the smote level to rest of the varaible

train1<-rbind(train_not_vrecom,train_remaining)
table(train1$Class)

```



```{r}
#install.packages("glmnet")
library(glmnet)
library(Matrix)

reg <- model.matrix(Class~., data = train1)
reg1 <- model.matrix(test$Class~., data = test)

 lm = cv.glmnet(reg,train1$Class,family = "multinomial",alpha =1)
 lm$lambda.min
log_reg<-glmnet(reg,train1$Class,family = "multinomial",alpha =0,lambda = lm$lambda.min)


#  x_train <- model.matrix( ~ .-1, train[,features])






```

```{r}
summary(log_reg)
```

```{r}
library(MASS)
library(caret)
preds_test_lr <- predict(log_reg, reg1,type = "class")
preds_train_lr<-predict(log_reg, reg,type = "class")
#pred_test<-as.data.frame(preds_test_lr)
#pred_train<-as.data.frame(preds_train_lr)
#class(pred_test)
#class(pred_train)
#pred_test[1]
#pred_train[1]
#length(test$Class)
#table(preds_test_lr, test$Class)


confusionMatrix(preds_test_lr, test$Class)

confusionMatrix(preds_train_lr, train1$Class)

```



```{r}

```

```{r}



```

